{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition Project - Structural Defect Recognition\n",
    "---------------------------------------------------------------\n",
    "## Data Collection\n",
    "\n",
    "### Section Objectives\n",
    " - Find relevant dataset from Kaggle\n",
    " - Collect the data\n",
    " - Preprocess data, checking for outlier images or irrelevant files\n",
    " - Divide dataset into the following subsets: Train, Test and Validation; at the ratio 0.7, 0.2, 0.1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r /workspaces/ML_Project_Image_Recognition/requirements.txt --silent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'workspaces/ML_Project_Image_Recognition'\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f\"Directory '{directory}' created.\")\n",
    "else:\n",
    "    print(f\"Directory '{directory}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('workspaces/ML_Project_Image_Recognition')\n",
    "print(\"This is your set Working Directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kaggle==1.5.12 --silent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_CONFIG_DIR'] = '/workspaces/ML_Project_Image_Recognition'\n",
    "!chmod 600 /workspaces/ML_Project_Image_Recognition/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_destination_folder = \"/workspaces/ML_Project_Image_Recognition/inputs/cracks_dataset_new\"\n",
    "os.makedirs(new_destination_folder, exist_ok=True)\n",
    "print(f\"Created new folder: {new_destination_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling dataset from Kaggle - (add here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KaggleDatasetPath = \"aniruddhsharma/structural-defects-network-concrete-crack-images\"\n",
    "DestinationFolder = \"/workspaces/ML_Project_Image_Recognition/inputs/cracks_dataset_new\"   \n",
    "os.makedirs(DestinationFolder, exist_ok=True)\n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = DestinationFolder + '/download.zip'\n",
    "if os.path.exists(zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DestinationFolder)\n",
    "    os.remove(zip_file_path)  \n",
    "else:\n",
    "    print(f\"File not found: {zip_file_path}\")\n",
    "    print(\"Listing files in the destination folder:\")\n",
    "    print(os.listdir(DestinationFolder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(DestinationFolder + '/structural-defects-network-concrete-crack-images.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(DestinationFolder)  \n",
    "\n",
    "os.remove(DestinationFolder + '/structural-defects-network-concrete-crack-images.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Checking for and removing any non-images from the downloaded dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_image_file(my_data_dir):\n",
    "    image_extensions = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "    for category in os.listdir(my_data_dir):  # Walls, Decks, Pavements\n",
    "        category_path = os.path.join(my_data_dir, category)\n",
    "        if not os.path.isdir(category_path):\n",
    "            continue\n",
    "\n",
    "        for class_name in os.listdir(category_path):  # Cracked, Non-Cracked\n",
    "            class_path = os.path.join(category_path, class_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "\n",
    "            total_images = 0\n",
    "            removed_files = 0\n",
    "\n",
    "            for file in os.listdir(class_path):\n",
    "                file_path = os.path.join(class_path, file)\n",
    "                if not file.lower().endswith(image_extensions):\n",
    "                    os.remove(file_path)\n",
    "                    removed_files += 1\n",
    "                else:\n",
    "                    total_images += 1\n",
    "\n",
    "            print(f\"{category}/{class_name} - {total_images} images, {removed_files} non-image files removed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_non_image_file(my_data_dir='/workspaces/ML_Project_Image_Recognition/inputs/cracks_dataset_new')\n",
    "\n",
    "fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing Dataset\n",
    "As mentioned previously, the dataset must be split into three partitions: a training set; a validation set and a testing set - in the ratio of 0.7, 0.1, 0.2 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
    "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
    "        print(\"Ratios must sum to 1.0\")\n",
    "        return\n",
    "\n",
    "    classes = os.listdir(my_data_dir)\n",
    "    base_output_dir = os.path.dirname(my_data_dir)\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_path = os.path.join(my_data_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        images = [img for img in os.listdir(class_path) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        random.shuffle(images)\n",
    "\n",
    "        n_total = len(images)\n",
    "        n_train = int(n_total * train_set_ratio)\n",
    "        n_val = int(n_total * validation_set_ratio)\n",
    "\n",
    "        splits = {\n",
    "            'train': images[:n_train],\n",
    "            'val': images[n_train:n_train + n_val],\n",
    "            'test': images[n_train + n_val:]\n",
    "        }\n",
    "\n",
    "        for split_name, split_images in splits.items():\n",
    "            split_dir = os.path.join(base_output_dir, split_name, os.path.basename(my_data_dir), class_name)\n",
    "            os.makedirs(split_dir, exist_ok=True)\n",
    "            for img_name in split_images:\n",
    "                src_path = os.path.join(class_path, img_name)\n",
    "                dst_path = os.path.join(split_dir, img_name)\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "\n",
    "        print(f\"{os.path.basename(my_data_dir)} / {class_name}: {n_total} â†’ {len(splits['train'])} train, {len(splits['val'])} val, {len(splits['test'])} test.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = ['Walls', 'Pavements', 'Decks']\n",
    "base_data_dir = os.path.join('..', 'inputs', 'cracks_dataset_new') \n",
    "\n",
    "for dtype in data_types:\n",
    "    full_path = os.path.join(base_data_dir, dtype)\n",
    "    print(f\"Checking: {full_path}\")  \n",
    "    if os.path.exists(full_path):\n",
    "        split_train_validation_test_images(\n",
    "            my_data_dir=full_path,\n",
    "            train_set_ratio=0.7,\n",
    "            validation_set_ratio=0.1,\n",
    "            test_set_ratio=0.2\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Directory not found: {full_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
