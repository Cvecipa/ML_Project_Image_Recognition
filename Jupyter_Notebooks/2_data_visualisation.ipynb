{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition Project - Structural Defect Recognition\n",
    "---------------------------------------------------------------\n",
    "## Data Visualisation\n",
    "\n",
    "### Section Objectives\n",
    " - Complete the project objective and answer the business requirements by training the -\n",
    "\n",
    " --------------------------------------------------------------\n",
    " ### Inputs\n",
    " inputs/cracks_dataset_new/test\n",
    "  inputs/cracks_dataset_new/train\n",
    "   inputs/cracks_dataset_new/validation\n",
    "\n",
    "----------------------------------------------------------------\n",
    "### Outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from matplotlib.image import imread\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import joblib\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspaces/ML_Project_Image_Recognition')\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Input and Output Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'inputs/cracks_dataset_new' \n",
    "\n",
    "train_path = os.path.join(base_path, 'train')\n",
    "val_path = os.path.join(base_path, 'val')\n",
    "test_path = os.path.join(base_path, 'test')\n",
    "\n",
    "datasets = os.listdir(train_path)\n",
    "print(\"Detected datasets in training set:\", datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v1'\n",
    "output_path = os.path.join('outputs', version)\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    print(f\"Created output folder at: {output_path}\")\n",
    "else:\n",
    "    print(f\"Output folder already exists: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Dataset Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset_path = os.path.join(train_path, dataset)\n",
    "    if os.path.isdir(dataset_path):\n",
    "        labels = os.listdir(dataset_path)\n",
    "        dataset_labels[dataset] = labels\n",
    "\n",
    "print(\"Dataset → Classes:\")\n",
    "for k, v in dataset_labels.items():\n",
    "    print(f\"• {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_distribution(base_path, dataset_name, save_path=None):\n",
    "    label_counts = {}\n",
    "\n",
    "    dataset_path = os.path.join(base_path, dataset_name)\n",
    "    for label in os.listdir(dataset_path):\n",
    "        label_path = os.path.join(dataset_path, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            label_counts[label] = len([\n",
    "                f for f in os.listdir(label_path)\n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "            ])\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.barplot(x=list(label_counts.keys()), y=list(label_counts.values()), ax=ax)\n",
    "    ax.set_title(f\"Label Distribution in {dataset_name}\")\n",
    "    ax.set_xlabel(\"Class\")\n",
    "    ax.set_ylabel(\"Number of Images\")\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Saved label distribution plot for {dataset_name} at {save_path}\")\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['Walls', 'Decks', 'Pavements']:\n",
    "    plot_label_distribution(\n",
    "        base_path=os.path.join(train_path),\n",
    "        dataset_name=dataset,\n",
    "        save_path=os.path.join(output_path, f\"label_distribution_{dataset}.png\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_dimensions(dataset_name):\n",
    "    dim1, dim2 = [], []\n",
    "    print(f\"\\n Processing image sizes for: {dataset_name}\")\n",
    "\n",
    "    for label in dataset_labels[dataset_name]:  \n",
    "        class_path = os.path.join(train_path, dataset_name, label)\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            try:\n",
    "                img = imread(img_path)\n",
    "                h, w = img.shape[:2]\n",
    "                dim1.append(h)\n",
    "                dim2.append(w)\n",
    "            except:\n",
    "                continue  \n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.scatterplot(x=dim2, y=dim1, alpha=0.2)\n",
    "    ax.set_xlabel(\"Width (px)\")\n",
    "    ax.set_ylabel(\"Height (px)\")\n",
    "    ax.set_title(f\"Image Size Distribution — {dataset_name}\")\n",
    "\n",
    "    mean_w = int(np.mean(dim2))\n",
    "    mean_h = int(np.mean(dim1))\n",
    "    ax.axvline(mean_w, color='r', linestyle='--', label=f\"Mean Width: {mean_w}px\")\n",
    "    ax.axhline(mean_h, color='g', linestyle='--', label=f\"Mean Height: {mean_h}px\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return mean_h, mean_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walls_shape = plot_image_dimensions('Walls')\n",
    "decks_shape = plot_image_dimensions('Decks')\n",
    "pavements_shape = plot_image_dimensions('Pavements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (256, 256, 3)\n",
    "print(\"Image shape to be saved:\", image_shape)\n",
    "\n",
    "joblib.dump(image_shape, os.path.join(output_path, \"image_shape.pkl\"))\n",
    "print(f\"Image shape saved to: {output_path}/image_shape.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load images into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def load_image_as_array(data_dir, dataset_name, image_shape=(256, 256), n_images_per_label=30, cache=True):\n",
    "    cache_file = os.path.join(output_path, f\"{dataset_name}_Xy_cache_{n_images_per_label}.pkl\")\n",
    "\n",
    "    if cache and os.path.exists(cache_file):\n",
    "        print(f\"Loading cached data for {dataset_name} from {cache_file}\")\n",
    "        return joblib.load(cache_file)\n",
    "\n",
    "    X, y = [], []\n",
    "    labels = dataset_labels[dataset_name]\n",
    "\n",
    "    for label in labels:\n",
    "        label_path = os.path.join(data_dir, dataset_name, label)\n",
    "        counter = 0\n",
    "\n",
    "        for file_name in os.listdir(label_path):\n",
    "            if counter >= n_images_per_label:\n",
    "                break\n",
    "\n",
    "            img_path = os.path.join(label_path, file_name)\n",
    "            try:\n",
    "                img = image.load_img(img_path, target_size=image_shape)\n",
    "                img_array = image.img_to_array(img) / 255.0\n",
    "                X.append(img_array)\n",
    "                y.append(label)\n",
    "                counter += 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if cache:\n",
    "        joblib.dump((X, y), cache_file)\n",
    "        print(f\"Saved cache to {cache_file}\")\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_walls, y_walls = load_image_as_array(train_path, dataset_name='Walls', image_shape=(256, 256), n_images_per_label=30)\n",
    "\n",
    "print(\"Loaded shape:\", X_walls.shape)\n",
    "print(\"Labels:\", np.unique(y_walls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_variability_per_labels(X, y, dataset_name, figsize=(12, 5), save_image=False):\n",
    "    for label in np.unique(y):\n",
    "        sns.set_style(\"white\")\n",
    "\n",
    "        mask = y == label\n",
    "        images = X[mask]\n",
    "\n",
    "        avg_img = np.mean(images, axis=0)\n",
    "        std_img = np.std(images, axis=0)\n",
    "\n",
    "        print(f\"Dataset: {dataset_name} | Class: {label}\")\n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "        axes[0].imshow(avg_img)\n",
    "        axes[0].set_title(f\"Mean Image — {label}\")\n",
    "        axes[1].imshow(std_img)\n",
    "        axes[1].set_title(f\"Variability — {label}\")\n",
    "\n",
    "        for ax in axes:\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_image:\n",
    "            filename = f\"{output_path}/mean_std_{dataset_name}_{label}.png\"\n",
    "            plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "            print(f\"Saved to {filename}\")\n",
    "        else:\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['Walls', 'Decks', 'Pavements']:\n",
    "    print(f\"\\n Loading and visualizing: {dataset}\")\n",
    "    X, y = load_image_as_array(train_path, dataset_name=dataset, image_shape=(256, 256), n_images_per_label=30)\n",
    "    plot_mean_variability_per_labels(X=X, y=y, dataset_name=dataset, save_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_between_avg_images(X, y, label_1, label_2, dataset_name, figsize=(15, 5), save_image=False):\n",
    "    \"\"\"Compute and visualize the difference between average images of two labels.\"\"\"\n",
    "    if label_1 not in np.unique(y) or label_2 not in np.unique(y):\n",
    "        print(f\"Labels must be in {np.unique(y)}\")\n",
    "        return\n",
    "\n",
    "    # Get images for each label\n",
    "    images_1 = X[y == label_1]\n",
    "    images_2 = X[y == label_2]\n",
    "\n",
    "    # Compute mean images\n",
    "    avg_img_1 = np.mean(images_1, axis=0)\n",
    "    avg_img_2 = np.mean(images_2, axis=0)\n",
    "\n",
    "    # Compute difference\n",
    "    diff_img = avg_img_1 - avg_img_2\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "    axes[0].imshow(avg_img_1)\n",
    "    axes[0].set_title(f\"Avg: {label_1}\")\n",
    "    axes[1].imshow(avg_img_2)\n",
    "    axes[1].set_title(f\"Avg: {label_2}\")\n",
    "    axes[2].imshow(diff_img)\n",
    "    axes[2].set_title(f\"Difference: {label_1} - {label_2}\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_image:\n",
    "        filename = f\"{output_path}/diff_{dataset_name}_{label_1}_vs_{label_2}.png\"\n",
    "        plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Saved: {filename}\")\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['Walls', 'Decks', 'Pavements']:\n",
    "    print(f\"\\nComparing Cracked vs Non-Cracked in: {dataset}\")\n",
    "    X, y = load_image_as_array(\n",
    "        data_dir=train_path,\n",
    "        dataset_name=dataset,\n",
    "        image_shape=(256, 256),\n",
    "        n_images_per_label=30\n",
    "    )\n",
    "    diff_between_avg_images(\n",
    "        X, y,\n",
    "        label_1='Cracked',\n",
    "        label_2='Non-cracked',\n",
    "        dataset_name=dataset,\n",
    "        save_image=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def image_montage(dir_path, dataset_name, label, nrows=3, ncols=3, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Display a montage of random images for a specific dataset and label.\n",
    "    \"\"\"\n",
    "    label_dir = os.path.join(dir_path, dataset_name, label)\n",
    "    all_images = os.listdir(label_dir)\n",
    "\n",
    "    if len(all_images) < nrows * ncols:\n",
    "        print(f\"Not enough images in {dataset_name}/{label} to create a {nrows}x{ncols} montage.\")\n",
    "        return\n",
    "\n",
    "    sample_images = random.sample(all_images, nrows * ncols)\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, img_name in enumerate(sample_images):\n",
    "        img_path = os.path.join(label_dir, img_name)\n",
    "        img = imread(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f\"{label}\", fontsize=10)\n",
    "\n",
    "    plt.suptitle(f\"{dataset_name} — {label} (Sample Images)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['Walls', 'Decks', 'Pavements']:\n",
    "    for label in dataset_labels[dataset]:\n",
    "        print(f\"\\nMontage: {dataset}/{label}\")\n",
    "        image_montage(train_path, dataset_name=dataset, label=label, nrows=3, ncols=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
