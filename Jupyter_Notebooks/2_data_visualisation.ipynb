{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition Project - Structural Defect Recognition\n",
    "---------------------------------------------------------------\n",
    "## Data Visualisation\n",
    "\n",
    "### Section Objectives\n",
    " - Complete the project objective and answer the business requirements by training the -\n",
    "\n",
    " --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from matplotlib.image import imread\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import joblib\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspaces/ML_Project_Image_Recognition')\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Input and Output Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'inputs/cracks_dataset_new' \n",
    "\n",
    "train_path = os.path.join(base_path, 'train')\n",
    "val_path = os.path.join(base_path, 'val')\n",
    "test_path = os.path.join(base_path, 'test')\n",
    "\n",
    "datasets = os.listdir(train_path)\n",
    "print(\"Detected datasets in training set:\", datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v1'\n",
    "output_path = os.path.join('outputs', version)\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    print(f\"Created output folder at: {output_path}\")\n",
    "else:\n",
    "    print(f\"Output folder already exists: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Dataset Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset_path = os.path.join(train_path, dataset)\n",
    "    if os.path.isdir(dataset_path):\n",
    "        labels = os.listdir(dataset_path)\n",
    "        dataset_labels[dataset] = labels\n",
    "\n",
    "print(\"Dataset → Classes:\")\n",
    "for k, v in dataset_labels.items():\n",
    "    print(f\"• {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_dimensions(dataset_name):\n",
    "    dim1, dim2 = [], []\n",
    "    print(f\"\\n Processing image sizes for: {dataset_name}\")\n",
    "\n",
    "    for label in dataset_labels[dataset_name]:  \n",
    "        class_path = os.path.join(train_path, dataset_name, label)\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            try:\n",
    "                img = imread(img_path)\n",
    "                h, w = img.shape[:2]\n",
    "                dim1.append(h)\n",
    "                dim2.append(w)\n",
    "            except:\n",
    "                continue  \n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.scatterplot(x=dim2, y=dim1, alpha=0.2)\n",
    "    ax.set_xlabel(\"Width (px)\")\n",
    "    ax.set_ylabel(\"Height (px)\")\n",
    "    ax.set_title(f\"Image Size Distribution — {dataset_name}\")\n",
    "\n",
    "    mean_w = int(np.mean(dim2))\n",
    "    mean_h = int(np.mean(dim1))\n",
    "    ax.axvline(mean_w, color='r', linestyle='--', label=f\"Mean Width: {mean_w}px\")\n",
    "    ax.axhline(mean_h, color='g', linestyle='--', label=f\"Mean Height: {mean_h}px\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return mean_h, mean_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walls_shape = plot_image_dimensions('Walls')\n",
    "decks_shape = plot_image_dimensions('Decks')\n",
    "pavements_shape = plot_image_dimensions('Pavements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (256, 256, 3)\n",
    "print(\"Image shape to be saved:\", image_shape)\n",
    "\n",
    "joblib.dump(image_shape, os.path.join(output_path, \"image_shape.pkl\"))\n",
    "print(f\"Image shape saved to: {output_path}/image_shape.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load images into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def load_image_as_array(data_dir, dataset_name, image_shape=(256, 256), n_images_per_label=30):\n",
    "    X, y = [], []\n",
    "    labels = dataset_labels[dataset_name]\n",
    "\n",
    "    for label in labels:\n",
    "        label_path = os.path.join(data_dir, dataset_name, label)\n",
    "        counter = 0\n",
    "\n",
    "        for file_name in os.listdir(label_path):\n",
    "            if counter >= n_images_per_label:\n",
    "                break\n",
    "\n",
    "            img_path = os.path.join(label_path, file_name)\n",
    "            try:\n",
    "                img = image.load_img(img_path, target_size=image_shape)\n",
    "                img_array = image.img_to_array(img) / 255.0 \n",
    "                X.append(img_array)\n",
    "                y.append(label)\n",
    "                counter += 1\n",
    "            except:\n",
    "                continue  \n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_walls, y_walls = load_image_as_array(train_path, dataset_name='Walls', image_shape=(256, 256), n_images_per_label=30)\n",
    "\n",
    "print(\"Loaded shape:\", X_walls.shape)\n",
    "print(\"Labels:\", np.unique(y_walls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_variability_per_labels(X, y, dataset_name, figsize=(12, 5), save_image=False):\n",
    "    for label in np.unique(y):\n",
    "        sns.set_style(\"white\")\n",
    "\n",
    "        mask = y == label\n",
    "        images = X[mask]\n",
    "\n",
    "        avg_img = np.mean(images, axis=0)\n",
    "        std_img = np.std(images, axis=0)\n",
    "\n",
    "        print(f\"Dataset: {dataset_name} | Class: {label}\")\n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "        axes[0].imshow(avg_img)\n",
    "        axes[0].set_title(f\"Mean Image — {label}\")\n",
    "        axes[1].imshow(std_img)\n",
    "        axes[1].set_title(f\"Variability — {label}\")\n",
    "\n",
    "        for ax in axes:\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_image:\n",
    "            filename = f\"{output_path}/mean_std_{dataset_name}_{label}.png\"\n",
    "            plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "            print(f\"Saved to {filename}\")\n",
    "        else:\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['Walls', 'Decks', 'Pavements']:\n",
    "    print(f\"\\n Loading and visualizing: {dataset}\")\n",
    "    X, y = load_image_as_array(train_path, dataset_name=dataset, image_shape=(256, 256), n_images_per_label=30)\n",
    "    plot_mean_variability_per_labels(X=X, y=y, dataset_name=dataset, save_image=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
