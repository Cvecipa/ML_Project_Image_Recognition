{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread\n",
    "import joblib\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspaces/ML_Project_Image_Recognition')\n",
    "print(\"New working directory set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'inputs/cracks_dataset_new'\n",
    "train_path = os.path.join(data_dir, 'train')\n",
    "val_path = os.path.join(data_dir, 'val')\n",
    "test_path = os.path.join(data_dir, 'test')\n",
    "\n",
    "version = 'v1'\n",
    "output_path = os.path.join('outputs', version)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "print(f\"Output folder: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = joblib.load(f'{output_path}/image_shape.pkl')\n",
    "print(\"Image shape loaded:\", image_shape)\n",
    "\n",
    "class_indices = joblib.load(f'{output_path}/class_indices.pkl')\n",
    "labels = list(class_indices.keys())\n",
    "print(\"Class labels:\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation \n",
    " - Augmenting only the \"Cracked\" images to create image diversity when training as the disparity between cracked and non-cracked images is quite large as noted in notebook 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_gen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "non_augmented_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def create_combined_generator(structure_name, image_shape=(256, 256), batch_size=32):\n",
    "    cracked_dir = os.path.join(train_path, structure_name, \"Cracked\")\n",
    "    non_cracked_dir = os.path.join(train_path, structure_name, \"Non-cracked\")\n",
    "\n",
    "    cracked_generator = augmented_gen.flow_from_directory(\n",
    "        directory=os.path.join(train_path, structure_name),\n",
    "        classes=[\"Cracked\"],\n",
    "        target_size=image_shape[:2],\n",
    "        class_mode='binary',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    non_cracked_generator = non_augmented_gen.flow_from_directory(\n",
    "        directory=os.path.join(train_path, structure_name),\n",
    "        classes=[\"Non-cracked\"],\n",
    "        target_size=image_shape[:2],\n",
    "        class_mode='binary',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    def combined_gen():\n",
    "        while True:\n",
    "            cracked_imgs, cracked_labels = cracked_generator.next()\n",
    "            non_imgs, non_labels = non_cracked_generator.next()\n",
    "\n",
    "            X = np.concatenate((cracked_imgs, non_imgs), axis=0)\n",
    "            y = np.concatenate((cracked_labels, non_labels), axis=0)\n",
    "\n",
    "            indices = np.arange(len(X))\n",
    "            np.random.shuffle(indices)\n",
    "            yield X[indices], y[indices]\n",
    "\n",
    "    return combined_gen(), len(cracked_generator.filenames) + len(non_cracked_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walls_train_gen, walls_total_images = create_combined_generator(\"Walls\")\n",
    "decks_train_gen, decks_total_images = create_combined_generator(\"Decks\")\n",
    "pavements_train_gen, pavements_total_images = create_combined_generator(\"Pavements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling\n",
    " - Avoiding augmentation on the Test and Validation sets and opting instead for just rescaling, this is to reflect real world images when testing the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def create_eval_generator(base_path, structure_name, batch_size=32):\n",
    "    return rescale_gen.flow_from_directory(\n",
    "        directory=os.path.join(base_path, structure_name),\n",
    "        target_size=image_shape[:2],\n",
    "        class_mode='binary',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walls_val_gen = create_eval_generator(val_path, \"Walls\")\n",
    "decks_val_gen = create_eval_generator(val_path, \"Decks\")\n",
    "pavements_val_gen = create_eval_generator(val_path, \"Pavements\")\n",
    "\n",
    "walls_test_gen = create_eval_generator(test_path, \"Walls\")\n",
    "decks_test_gen = create_eval_generator(test_path, \"Decks\")\n",
    "pavements_test_gen = create_eval_generator(test_path, \"Pavements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_augmented_montage(generator, structure_name, output_path, n_images=9):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from math import ceil\n",
    "\n",
    "    imgs, labels = next(generator)\n",
    "    imgs = imgs[:n_images]\n",
    "\n",
    "    n_cols = 3\n",
    "    n_rows = ceil(n_images / n_cols)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"Augmented\")\n",
    "\n",
    "    for i in range(n_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(output_path, f\"augmented_samples_{structure_name}.png\")\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_augmented_montage(\n",
    "    augmented_gen.flow_from_directory(\n",
    "        directory=os.path.join(train_path, \"Walls\"),\n",
    "        classes=[\"Cracked\"],\n",
    "        target_size=image_shape[:2],\n",
    "        class_mode='binary',\n",
    "        batch_size=9,\n",
    "        shuffle=True\n",
    "    ),\n",
    "    \"Walls\", output_path\n",
    ")\n",
    "\n",
    "save_augmented_montage(\n",
    "    augmented_gen.flow_from_directory(\n",
    "        directory=os.path.join(train_path, \"Decks\"),\n",
    "        classes=[\"Cracked\"],\n",
    "        target_size=image_shape[:2],\n",
    "        class_mode='binary',\n",
    "        batch_size=9,\n",
    "        shuffle=True\n",
    "    ),\n",
    "    \"Decks\", output_path\n",
    ")\n",
    "\n",
    "save_augmented_montage(\n",
    "    augmented_gen.flow_from_directory(\n",
    "        directory=os.path.join(train_path, \"Pavements\"),\n",
    "        classes=[\"Cracked\"],\n",
    "        target_size=image_shape[:2],\n",
    "        class_mode='binary',\n",
    "        batch_size=9,\n",
    "        shuffle=True\n",
    "    ),\n",
    "    \"Pavements\", output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "montage_files = [\n",
    "    os.path.join(output_path, \"augmented_samples_Walls.png\"),\n",
    "    os.path.join(output_path, \"augmented_samples_Decks.png\"),\n",
    "    os.path.join(output_path, \"augmented_samples_Pavements.png\")\n",
    "]\n",
    "\n",
    "for file in montage_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"Displaying: {os.path.basename(file)}\")\n",
    "        display(Image(filename=file))\n",
    "    else:\n",
    "        print(f\"File not found: {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_model_1(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_1 = create_tf_model_1(input_shape=image_shape)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history_tf_model_1 = tf_model_1.fit(\n",
    "    walls_train_gen,\n",
    "    steps_per_epoch=walls_total_images // 16,\n",
    "    validation_data=walls_val_gen,\n",
    "    validation_steps=walls_val_gen.samples // 16,\n",
    "    epochs=25,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_1.save(os.path.join(output_path, \"tf_model_1_walls.h5\"))\n",
    "joblib.dump(history_tf_model_1.history, os.path.join(output_path, \"history_tf_model_1_walls.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv 3.8.12)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
